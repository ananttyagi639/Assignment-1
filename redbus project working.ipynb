{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa8fb66-6356-47de-ab0a-074fcb1f1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import mysql.connector as sconn\n",
    "from mysql.connector import Error\n",
    "\n",
    "# ------------------------------------------------ Selenium Web Scraping ------------------------------------------------ #\n",
    "\n",
    "def open_url(url):\n",
    "    \"\"\"Opens the Redbus website.\"\"\"\n",
    "    try:\n",
    "        # Optionally run in headless mode\n",
    "        no_page = Options()\n",
    "        no_page.add_argument('--headless')\n",
    "        # driver = webdriver.Chrome(options=no_page)  # Headless\n",
    "        driver = webdriver.Chrome()  # Visible browser\n",
    "        driver.get(url)\n",
    "        print(\"URL opened successfully\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred when initializing Webdriver:\", e)\n",
    "    return driver\n",
    "\n",
    "def maximize_window(driver):\n",
    "    \"\"\"Maximizes the browser window.\"\"\"\n",
    "    try:\n",
    "        driver.maximize_window()\n",
    "        print(\"Window maximized\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred when maximizing the window:\", e)\n",
    "\n",
    "def scrolling(driver):\n",
    "    \"\"\"Scrolls down the page.\"\"\"\n",
    "    try:\n",
    "        driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(1)\n",
    "        print(\"Page scrolled\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred when scrolling the page:\", e)\n",
    "\n",
    "def press_viewall(driver):\n",
    "    \"\"\"Selects and presses the 'View All' button.\"\"\"\n",
    "    try:\n",
    "        view_all = driver.find_elements(By.XPATH, \"//a[@class='OfferSection__ViewAllText-sc-16xojcc-1 eVcjqm']\")\n",
    "        ref = view_all[1].get_attribute('href')\n",
    "        time.sleep(2)\n",
    "        driver.get(ref)  # Navigate to rtc-directory\n",
    "        print(\"View all button pressed\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred when selecting 'View All' button:\", e)\n",
    "    return driver\n",
    "\n",
    "def fetch_state_names(driver):\n",
    "    \"\"\"Fetches the state names and their links.\"\"\"\n",
    "    state_name = []\n",
    "    state_links = []\n",
    "    try:\n",
    "        state_elements = driver.find_elements(By.XPATH, \"//div[@class='D113_ul_rtc']/ul/li/a\")\n",
    "        for element in state_elements:\n",
    "            state_name.append(element.text)\n",
    "            state_links.append(element.get_attribute('href'))\n",
    "        print(f\"State names fetched: {len(state_links)}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error when fetching state names:\", e)\n",
    "    return state_links, state_name\n",
    "\n",
    "def route_name_ref(driver, state_links, state_name):\n",
    "    \"\"\"Fetches route names and their links.\"\"\"\n",
    "    route_name_link = []\n",
    "    route_link = []\n",
    "    route_num = []\n",
    "    count = 0\n",
    "    route_no = 1\n",
    "    state_index = 0\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    try:\n",
    "        for link in state_links:\n",
    "            if count >= 11:\n",
    "                break\n",
    "            driver.get(link)\n",
    "            time.sleep(2)\n",
    "\n",
    "            page_no = driver.find_elements(By.XPATH, \"//div[@class='DC_117_paginationTable']/div\")\n",
    "            print(f'{link} - page count - {len(page_no)}')\n",
    "\n",
    "            if len(page_no) != 0:\n",
    "                try:\n",
    "                    route = driver.find_elements(By.XPATH, \"//div[@class='route_link']/div/a\")\n",
    "                    for j in route:\n",
    "                        route_link.append(j.get_attribute('href'))\n",
    "                        route_name_link.append((route_no, state_name[state_index], j.get_attribute('title'), j.get_attribute('href')))\n",
    "                        route_num.append(route_no)\n",
    "                        route_no += 1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "                no = 0\n",
    "                page_number = 0\n",
    "                while no < len(page_no):\n",
    "                    try:\n",
    "                        pagination_container = wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@id='root']/div/div[4]/div[12]\")))\n",
    "                        next_page_button = pagination_container.find_element(By.XPATH, f'//div[contains(@class,\"DC_117_pageTabs\") and text()=\"{page_number + 1}\"]')\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "                        next_page_button.click()\n",
    "                        wait.until(EC.text_to_be_present_in_element((By.XPATH, \"//div[@class='DC_117_pageTabs DC_117_pageActive']\"), str(page_number + 1)))\n",
    "                        time.sleep(1)\n",
    "                        route = driver.find_elements(By.XPATH, \"//div[@class='route_link']/div/a\")\n",
    "                        for j in route:\n",
    "                            route_link.append(j.get_attribute('href'))\n",
    "                            route_name_link.append((route_no, state_name[state_index], j.get_attribute('title'), j.get_attribute('href')))\n",
    "                            route_num.append(route_no)\n",
    "                            route_no += 1\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                    no += 1\n",
    "                    page_number += 1\n",
    "                count += 1\n",
    "            state_index += 1\n",
    "        print(f\"Route names and links fetched: {len(route_name_link)}, Length of route link: {len(route_link)}\")\n",
    "        print(\"Total route_no\", route_num)\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred when scraping bus route and link:\", e)\n",
    "    return route_name_link, route_link, route_num\n",
    "\n",
    "def fetch_bus_datas(driver, route_link, no_route):\n",
    "    \"\"\"Fetches bus details from each route.\"\"\"\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    bus_datas = []\n",
    "    reference = 0\n",
    "    bus_no = 0\n",
    "    while reference < len(route_link):\n",
    "        driver.get(route_link[reference])\n",
    "        print(f\"Fetching data from route: {route_link[reference]}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "        try:\n",
    "            goverment_buses = wait.until(EC.visibility_of_element_located((By.XPATH, \"//div[@class='button']\")))\n",
    "            buttons = driver.find_elements(By.XPATH, \"//div[@class='button']\")\n",
    "            button_index = len(buttons) - 1\n",
    "            if len(buttons) != 0:\n",
    "                for _ in buttons:\n",
    "                    buttons[button_index].click()\n",
    "                    time.sleep(3)\n",
    "                    button_index -= 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        old_page = \"\"\n",
    "        looping = True\n",
    "        while looping:\n",
    "            driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
    "            time.sleep(1)\n",
    "            new_page = driver.page_source\n",
    "            if new_page == old_page:\n",
    "                looping = False\n",
    "            else:\n",
    "                old_page = new_page\n",
    "            total_bus = driver.find_elements(By.XPATH, \"//div[@class='clearfix row-one']\")\n",
    "            time.sleep(1)\n",
    "\n",
    "        for bus_l in total_bus:\n",
    "            try:\n",
    "                bus_name = bus_l.find_element(By.CSS_SELECTOR, \"div.travels.lh-24.f-bold.d-color\").text\n",
    "                bus_type = bus_l.find_element(By.CSS_SELECTOR, \"div.bus-type.f-12.m-top-16.l-color.evBus\").text\n",
    "                departing_time = bus_l.find_element(By.CSS_SELECTOR, \"div.dp-time.f-19.d-color.f-bold\").text\n",
    "                duration = bus_l.find_element(By.CSS_SELECTOR, \"div.dur.l-color.lh-24\").text\n",
    "                reaching_time = bus_l.find_element(By.CSS_SELECTOR, \"div.bp-time.f-19.d-color.disp-Inline\").text\n",
    "                star_rating = bus_l.find_element(By.CSS_SELECTOR, \"div.rating-sec span\").text\n",
    "                price = bus_l.find_element(By.CSS_SELECTOR, \"span.f-19.f-bold\").text\n",
    "                total_seat_availability = bus_l.find_element(By.CSS_SELECTOR, \".seat-left\").text\n",
    "                seat_availability = total_seat_availability.split()[0]\n",
    "\n",
    "                bus_datas.append((no_route[bus_no], bus_name, bus_type, departing_time, duration, reaching_time, star_rating, price, seat_availability))\n",
    "            except Exception as e:\n",
    "                continue\n",
    "\n",
    "        print(f\"Bus no: {bus_no} == Route no: {no_route[bus_no]}\")\n",
    "        bus_no += 1\n",
    "        reference += 1\n",
    "        print(f\"Total bus data entries fetched: {len(bus_datas)}\")\n",
    "    return bus_datas\n",
    "\n",
    "def quit_driver(driver):\n",
    "    \"\"\"Quits the WebDriver.\"\"\"\n",
    "    driver.quit()\n",
    "\n",
    "# Main Execution for Web Scraping\n",
    "url = \"https://www.redbus.in/\"\n",
    "\n",
    "driver = open_url(url)\n",
    "maximize_window(driver)\n",
    "scrolling(driver)\n",
    "driver = press_viewall(driver)\n",
    "\n",
    "link_states, state_name = fetch_state_names(driver)\n",
    "name_link_state, route_ref, route_number = route_name_ref(driver, link_states, state_name)\n",
    "bus_details = fetch_bus_datas(driver, route_ref, route_number)\n",
    "quit_driver(driver)\n",
    "\n",
    "# ------------------------------------------------- Data Processing ------------------------------------------------- #\n",
    "\n",
    "# Convert the bus details into a DataFrame\n",
    "bus_data = pd.DataFrame(data=bus_details, columns=['bus_no', 'bus_name', 'bus_type', 'departing_time', 'duration', 'reaching_time', 'star_rating', 'price', 'seat_availability'])\n",
    "\n",
    "# Convert star_rating to numeric, replace non-numeric values with 0\n",
    "bus_data['star_rating'] = pd.to_numeric(bus_data['star_rating'], errors='coerce').fillna(0)\n",
    "\n",
    "# Convert the route details into a DataFrame\n",
    "normal_route_data = pd.DataFrame(data=name_link_state, columns=['route_no', 'state_name', 'route_name', 'route_ref'])\n",
    "print(\"Length of route_data:\", len(normal_route_data))\n",
    "\n",
    "# Ensure bus_no and route_no match\n",
    "unique_bus_no = bus_data['bus_no']\n",
    "\n",
    "# Save bus data to CSV\n",
    "bus_data.to_csv('bus_data.csv', index=False)\n",
    "\n",
    "# Save route data to CSV\n",
    "normal_route_data.to_csv('route_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
